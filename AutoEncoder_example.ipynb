{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Autoencoder for MNIST (with GPU implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #will be used for creating directories, etc.\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dsets             #for downloading dataset\n",
    "import torchvision.transforms as transforms      #for transforming dataset into tensors\n",
    "\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ../data\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "#download MNIST dataset\n",
    "dataset = dsets.MNIST(root='../data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fbaf0887b50>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "\n",
    "# shuffle and prepare dataset with minibatches\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "print(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Autoencoder NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, in_dim=784, h_dim=100):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, h_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(h_dim, in_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 30     #size of the bottleneck layer\n",
    "\n",
    "# Create Autoencoder model\n",
    "ae = Autoencoder(in_dim=784, h_dim=hidden_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ae.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()     #Binary cross-entropy loss for each pixel\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to go through all the examples in each epoch, so number of iterations per epoch\n",
    "iter_per_epoch = len(data_loader)\n",
    "data_iter      = iter(data_loader) # data_iter is an iterator object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we want to view and save results on a fixed batch to visualize Autoencoder's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "dir_output = ('data/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "# save fixed inputs for debugging\n",
    "fixed_x, labels = next(data_iter)        #points to the first batch\n",
    "# torchvision.utils.save_image(Variable(fixed_x).data.cpu(), './data/real_images.png')\n",
    "print(fixed_x.size())\n",
    "# print(fixed_x.view(fixed_x.size(0), -1).size())\n",
    "fixed_x = to_var(fixed_x.view(fixed_x.size(0), -1))\n",
    "print(fixed_x.size())\n",
    "\n",
    "# fixed_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [100/600] Loss: 0.1033 Time: 0.83s\n",
      "Epoch [1/50], Iter [200/600] Loss: 0.1006 Time: 1.58s\n",
      "Epoch [1/50], Iter [300/600] Loss: 0.1087 Time: 2.33s\n",
      "Epoch [1/50], Iter [400/600] Loss: 0.0974 Time: 3.03s\n",
      "Epoch [1/50], Iter [500/600] Loss: 0.1026 Time: 3.74s\n",
      "Epoch [1/50], Iter [600/600] Loss: 0.0992 Time: 4.44s\n",
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    t0 = time()\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        \n",
    "        # flatten the image\n",
    "        images = to_var(images.view(images.size(0), -1))\n",
    "        out = ae(images)\n",
    "        loss = criterion(out, images)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()         # calculate gradients\n",
    "        optimizer.step()        # update parameters\n",
    "        \n",
    "        # display training process after every 100 iterations\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f Time: %.2fs' \n",
    "                %(epoch+1, num_epochs, i+1, len(dataset)//batch_size, loss.item(), time()-t0))\n",
    "            \n",
    "    # save the reconstructed images\n",
    "    reconst_images = ae(fixed_x)\n",
    "    print(reconst_images.size())\n",
    "    reconst_images = reconst_images.view(reconst_images.size(0), 1, 28, 28)\n",
    "#     torchvision.utils.save_image(reconst_images.data.cpu(), './data/reconst_images_%d.png' % (epoch+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
